{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ],
      "metadata": {
        "id": "uepuDQD-hB8y"
      },
      "id": "uepuDQD-hB8y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/smsspamcollection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HgBYH-2h9Ph",
        "outputId": "ed9b1ae9-f8a1-4f0c-cc9f-3b66034ecb06"
      },
      "id": "-HgBYH-2h9Ph",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/smsspamcollection.zip\n",
            "replace SMSSpamCollection? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: readme                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31bc851",
      "metadata": {
        "id": "e31bc851"
      },
      "source": [
        "### Create a spark session and import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf86e46",
      "metadata": {
        "id": "dcf86e46"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c7df9e",
      "metadata": {
        "id": "90c7df9e"
      },
      "source": [
        "### Read the readme file to learn more about the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d00718f",
      "metadata": {
        "id": "2d00718f"
      },
      "source": [
        "### Read the data into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUL505epjPSI"
      },
      "id": "uUL505epjPSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29914cf1",
      "metadata": {
        "id": "29914cf1"
      },
      "outputs": [],
      "source": [
        "df= spark.read.option(\"delimiter\", \"\\t\").csv('/content/SMSSpamCollection', inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3yWOIvAi9VW",
        "outputId": "8fe683b5-1cc8-4b81-eefb-322097d0dec6"
      },
      "id": "B3yWOIvAi9VW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "| _c0|                 _c1|\n",
            "+----+--------------------+\n",
            "| ham|Go until jurong p...|\n",
            "| ham|Ok lar... Joking ...|\n",
            "|spam|Free entry in 2 a...|\n",
            "| ham|U dun say so earl...|\n",
            "| ham|Nah I don't think...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182cd7f6",
      "metadata": {
        "id": "182cd7f6"
      },
      "source": [
        "### Print the schema"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY7BhrJ9jXUV",
        "outputId": "f71a0956-3ddc-4458-aa7d-7348097effe9"
      },
      "id": "iY7BhrJ9jXUV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b90cce7",
      "metadata": {
        "id": "2b90cce7"
      },
      "source": [
        "### Rename the first column to 'class' and second column to 'text'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= df.withColumnRenamed(\"_c0\",\"class\")\n",
        "data= data.withColumnRenamed(\"_c1\",\"text\")"
      ],
      "metadata": {
        "id": "Jor8uG3ljcWz"
      },
      "id": "Jor8uG3ljcWz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SSrKf_Ojz85",
        "outputId": "fea732ea-57ab-4d67-f9c0-79bed626eb2d"
      },
      "id": "9SSrKf_Ojz85",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e798d0",
      "metadata": {
        "id": "a3e798d0"
      },
      "source": [
        "### Show the first 10 rows from the dataframe\n",
        "- Show once with truncate=True and once with truncate=False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(10,truncate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtQbbctikd8s",
        "outputId": "dacf2ac4-6983-489a-a1ae-486af9c27ca7"
      },
      "id": "gtQbbctikd8s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|class|                text|\n",
            "+-----+--------------------+\n",
            "|  ham|Go until jurong p...|\n",
            "|  ham|Ok lar... Joking ...|\n",
            "| spam|Free entry in 2 a...|\n",
            "|  ham|U dun say so earl...|\n",
            "|  ham|Nah I don't think...|\n",
            "| spam|FreeMsg Hey there...|\n",
            "|  ham|Even my brother i...|\n",
            "|  ham|As per your reque...|\n",
            "| spam|WINNER!! As a val...|\n",
            "| spam|Had your mobile 1...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(10,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJmn1cIXkPt6",
        "outputId": "a91917dd-59f7-4f5b-9c5e-c627cd0d6909"
      },
      "id": "BJmn1cIXkPt6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|class|text                                                                                                                                                            |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                 |\n",
            "|ham  |Ok lar... Joking wif u oni...                                                                                                                                   |\n",
            "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     |\n",
            "|ham  |U dun say so early hor... U c already then say...                                                                                                               |\n",
            "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                                   |\n",
            "|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv             |\n",
            "|ham  |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                   |\n",
            "|ham  |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune|\n",
            "|spam |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.   |\n",
            "|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030      |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe744a9",
      "metadata": {
        "id": "2fe744a9"
      },
      "source": [
        "## Clean and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d693167",
      "metadata": {
        "id": "4d693167"
      },
      "source": [
        "### Create a new feature column contains the length of the text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5424a0cb",
      "metadata": {
        "id": "5424a0cb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as fn\n",
        "\n",
        "len_text = lambda s: len(s)\n",
        "len_text= fn.udf(len_text,IntegerType())\n",
        "data = data.withColumn(\"len_text\",len_text('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ea2de6",
      "metadata": {
        "id": "78ea2de6"
      },
      "source": [
        "### Show the new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qfo_LBAmDJa",
        "outputId": "ad9e491b-31be-4a1a-c5bf-53de18a743c9"
      },
      "id": "7qfo_LBAmDJa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------+\n",
            "|class|                text|len_text|\n",
            "+-----+--------------------+--------+\n",
            "|  ham|Go until jurong p...|     111|\n",
            "|  ham|Ok lar... Joking ...|      29|\n",
            "| spam|Free entry in 2 a...|     155|\n",
            "|  ham|U dun say so earl...|      49|\n",
            "|  ham|Nah I don't think...|      61|\n",
            "| spam|FreeMsg Hey there...|     147|\n",
            "|  ham|Even my brother i...|      77|\n",
            "|  ham|As per your reque...|     160|\n",
            "| spam|WINNER!! As a val...|     157|\n",
            "| spam|Had your mobile 1...|     154|\n",
            "|  ham|I'm gonna be home...|     109|\n",
            "| spam|SIX chances to wi...|     136|\n",
            "| spam|URGENT! You have ...|     155|\n",
            "|  ham|I've been searchi...|     196|\n",
            "|  ham|I HAVE A DATE ON ...|      35|\n",
            "| spam|XXXMobileMovieClu...|     149|\n",
            "|  ham|Oh k...i'm watchi...|      26|\n",
            "|  ham|Eh u remember how...|      81|\n",
            "|  ham|Fine if thats th...|      56|\n",
            "| spam|England v Macedon...|     155|\n",
            "+-----+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692e37a6",
      "metadata": {
        "id": "692e37a6"
      },
      "source": [
        "### Get the average text length for each class (give alias name to the average length column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('class').agg(fn.avg('len_text').alias(\"Avg. Lenght\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9HO5NC3mJXs",
        "outputId": "de79a8f9-9b9c-4981-b3c0-cf26567ebf94"
      },
      "id": "k9HO5NC3mJXs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|class|      Avg. Lenght|\n",
            "+-----+-----------------+\n",
            "|  ham|71.45431945307645|\n",
            "| spam|138.6706827309237|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e101af",
      "metadata": {
        "id": "d5e101af"
      },
      "source": [
        "## Feature Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838ad9dd",
      "metadata": {
        "id": "838ad9dd"
      },
      "source": [
        "### In this part you transform you raw text in to tf_idf model :\n",
        "- For more information about TF-IDF check the following link: <b>(Not needed for the test)</b>\n",
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225067d5",
      "metadata": {
        "id": "225067d5"
      },
      "source": [
        "### Perform the following steps to obtain TF-IDF:\n",
        "1. Import the required transformers/estimators for the subsequent steps.\n",
        "2. Create a <b>Tokenizer</b> from the text column.\n",
        "3. Create a <b>StopWordsRemover</b> to remove the <b>stop words</b> from the column obtained from the <b>Tokenizer</b>.\n",
        "4. Create a <b>CountVectorizer</b> after removing the <b>stop words</b>.\n",
        "5. Create the <b>TF-IDF</b> from the <b>CountVectorizer</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4eebf8",
      "metadata": {
        "id": "6a4eebf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72369aa-9dc9-443b-d95f-731c90348ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "|class|                text|len_text|               words|AfterRemovestopwords|             vectors|     tf-idf_features|\n",
            "+-----+--------------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "|  ham|Go until jurong p...|     111|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(262144,[38555,52...|\n",
            "|  ham|Ok lar... Joking ...|      29|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(262144,[51783,15...|\n",
            "| spam|Free entry in 2 a...|     155|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(262144,[9443,122...|\n",
            "|  ham|U dun say so earl...|      49|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(262144,[2306,332...|\n",
            "|  ham|Nah I don't think...|      61|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(262144,[25964,64...|\n",
            "| spam|FreeMsg Hey there...|     147|[freemsg, hey, th...|[freemsg, hey, da...|(13423,[10,60,139...|(262144,[19835,23...|\n",
            "|  ham|Even my brother i...|      77|[even, my, brothe...|[even, brother, l...|(13423,[10,53,103...|(262144,[103497,1...|\n",
            "|  ham|As per your reque...|     160|[as, per, your, r...|[per, request, 'm...|(13423,[125,184,4...|(262144,[12650,27...|\n",
            "| spam|WINNER!! As a val...|     157|[winner!!, as, a,...|[winner!!, valued...|(13423,[1,47,118,...|(262144,[4314,232...|\n",
            "| spam|Had your mobile 1...|     154|[had, your, mobil...|[mobile, 11, mont...|(13423,[0,1,13,27...|(262144,[1546,219...|\n",
            "|  ham|I'm gonna be home...|     109|[i'm, gonna, be, ...|[gonna, home, soo...|(13423,[18,43,120...|(262144,[12716,17...|\n",
            "| spam|SIX chances to wi...|     136|[six, chances, to...|[six, chances, wi...|(13423,[8,17,37,8...|(262144,[7415,161...|\n",
            "| spam|URGENT! You have ...|     155|[urgent!, you, ha...|[urgent!, won, 1,...|(13423,[13,30,47,...|(262144,[23209,35...|\n",
            "|  ham|I've been searchi...|     196|[i've, been, sear...|[searching, right...|(13423,[39,96,217...|(262144,[15585,41...|\n",
            "|  ham|I HAVE A DATE ON ...|      35|[i, have, a, date...|[date, sunday, wi...|(13423,[552,1697,...|(262144,[39504,13...|\n",
            "| spam|XXXMobileMovieClu...|     149|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13423,[30,109,11...|(262144,[26364,44...|\n",
            "|  ham|Oh k...i'm watchi...|      26|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13423,[82,214,47...|(262144,[18184,22...|\n",
            "|  ham|Eh u remember how...|      81|[eh, u, remember,...|[eh, u, remember,...|(13423,[0,2,49,13...|(262144,[12524,16...|\n",
            "|  ham|Fine if thats th...|      56|[fine, if, thats...|[fine, thats, wa...|(13423,[0,74,105,...|(262144,[37132,51...|\n",
            "| spam|England v Macedon...|     155|[england, v, mace...|[england, v, mace...|(13423,[4,30,33,5...|(262144,[16168,29...|\n",
            "+-----+--------------------+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,StopWordsRemover,CountVectorizer,HashingTF\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "wordsData = tokenizer.transform(data)\n",
        "stopwords = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"AfterRemovestopwords\")\n",
        "wordsData = stopwords.transform(wordsData)\n",
        "cv = CountVectorizer(inputCol=stopwords.getOutputCol(), outputCol=\"vectors\")\n",
        "vectorizer = cv.fit(wordsData)\n",
        "wordsData= vectorizer.transform(wordsData)\n",
        "# idf=IDF(inputCol=\"vectors\", outputCol=\"tf-idf_features\")\n",
        "# idfModel = idf.fit(wordsData)\n",
        "# wordsData = idfModel.transform(wordsData)\n",
        "\n",
        "idf = HashingTF(inputCol=\"AfterRemovestopwords\", outputCol=\"tf-idf_features\")\n",
        "wordsData = idf.transform(wordsData)\n",
        "wordsData.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b82756db",
      "metadata": {
        "id": "b82756db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1527ad65",
      "metadata": {
        "id": "1527ad65"
      },
      "source": [
        "- Convert the <b>class column</b> to index using <b>StringIndexer</b>\n",
        "- Create feature column from the <b>TF-IDF</b> and <b>lenght</b> columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf46159",
      "metadata": {
        "id": "aaf46159"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, Imputer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "stringIndexer = StringIndexer(inputCol=\"class\",\n",
        "                              outputCol=\"encode_class\",\n",
        "                             handleInvalid='skip')\n",
        "\n",
        "assemblerInputs =[\"vectors\",\"len_text\"]\n",
        "vecAssembler = VectorAssembler(inputCols=assemblerInputs,outputCol='features')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9d4c52",
      "metadata": {
        "id": "ad9d4c52"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9775d494",
      "metadata": {
        "id": "9775d494"
      },
      "source": [
        "## The Model\n",
        "- Create a <b>NaiveBayes</b> classifier with the default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57af0d5d",
      "metadata": {
        "id": "57af0d5d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "model = NaiveBayes(featuresCol='features',\n",
        "                      labelCol='encode_class',\n",
        "                      predictionCol='prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c7384e",
      "metadata": {
        "id": "54c7384e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dc14de63",
      "metadata": {
        "id": "dc14de63"
      },
      "source": [
        "## Pipeline\n",
        "### Create a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee0d1ca",
      "metadata": {
        "id": "8ee0d1ca"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[stringIndexer,\n",
        "                           vecAssembler,model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f82bab0",
      "metadata": {
        "id": "7f82bab0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f5d7efbe",
      "metadata": {
        "id": "f5d7efbe"
      },
      "source": [
        "### Split your data to trian and test data with ratios 0.7 and 0.3 respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2843d997",
      "metadata": {
        "id": "2843d997"
      },
      "outputs": [],
      "source": [
        "trainDF, testDF = wordsData.randomSplit([.7,.3],seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcea576",
      "metadata": {
        "id": "8bcea576"
      },
      "source": [
        "### Fit your Pipeline model to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5d4681",
      "metadata": {
        "id": "3c5d4681"
      },
      "outputs": [],
      "source": [
        "pipelineModel = pipeline.fit(trainDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228a3eb1",
      "metadata": {
        "id": "228a3eb1"
      },
      "source": [
        "### Perform predictions on tests dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14f4aab5",
      "metadata": {
        "id": "14f4aab5"
      },
      "outputs": [],
      "source": [
        "predDF = pipelineModel.transform(testDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce2885f",
      "metadata": {
        "id": "bce2885f"
      },
      "source": [
        "### Print the schema of the prediction dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predDF.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGkQdUQty40_",
        "outputId": "81d578be-f63e-4262-c6c4-8b9fdac1ba11"
      },
      "id": "kGkQdUQty40_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- len_text: integer (nullable = true)\n",
            " |-- words: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- AfterRemovestopwords: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- vectors: vector (nullable = true)\n",
            " |-- tf-idf_features: vector (nullable = true)\n",
            " |-- encode_class: double (nullable = false)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f27055",
      "metadata": {
        "id": "57f27055"
      },
      "source": [
        "## Model Evaluation\n",
        "- Use <b>MulticlassClassificationEvaluator</b> to calculate the <b>f1_score</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61911086",
      "metadata": {
        "id": "61911086"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "Evaluator= MulticlassClassificationEvaluator(predictionCol='prediction',\n",
        "                                         labelCol='encode_class',\n",
        "                                         metricName='f1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be706565",
      "metadata": {
        "id": "be706565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd4e8cd-1245-4962-f815-e801dbd40321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9758738064105548"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "Evaluator.evaluate(predDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1f9ba1",
      "metadata": {
        "id": "af1f9ba1",
        "outputId": "6dd58713-4247-48f8-f3ff-337f79ed3aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score is: 0.9664707489549014\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}